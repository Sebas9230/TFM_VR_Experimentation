# Designing Immersive Experiences in VR: Evaluation of Multisensory Stimuli and Interaction Methods

[![Summary of the 3 VR Minigames](https://img.youtube.com/vi/wEX7w1azYsc/0.jpg)](https://youtu.be/wEX7w1azYsc)

> 🎮 Click the image to watch a short video showcasing the three VR minigames.

## 📌 Overview

This project is the result of the Master’s Thesis developed within the **Master in Software and Systems (MUSS)** at **Universidad Politécnica de Madrid**. It explores how **multisensory stimuli** (spatial audio, haptic feedback, dynamic visuals) and **advanced interaction methods** (voice, gaze) influence **immersion** and **presence** in virtual reality environments.

Starting from a basic shooting prototype in Unity, the project evolves into an **experimental VR platform** composed of **three distinct minigames**, deployable in two system versions (SteamVR and OpenXR), and compatible with **HTC Vive Pro Eye** and **Meta Quest 3**.

## 🧩 Minigames

1. **ShooterScene** – A shooting minigame focused on spatial awareness and reaction time.
2. **ObstacleCourseScene** – An obstacle circuit testing motor coordination and locomotion.
3. **PuzzleScene** – A logic puzzle ("Who wears which hat?") that challenges reasoning and spatial manipulation.

Each minigame was designed to evaluate different aspects of human-computer interaction in VR.

## 🔧 Technologies and Devices

- **Engine**: Unity 2022.3.30f1
- **Frameworks**: OpenXR, SteamVR Plugin, XR Interaction Toolkit
- **Hardware**:
  - HTC Vive Pro Eye (with eye-tracking and Vive Trackers for simulated walking)
  - Meta Quest 3

## ⚙️ Key Features

- **Fully modular design**: Dynamic activation of stimuli and interaction modes.
- **Eye tracking**: Used for targeting and interaction in the shooter.
- **Voice commands**: Trigger the action with voice (e.g., saying "shoot").
- **Realistic locomotion**: Includes teleportation, joystick movement, and fake walking using foot trackers.
- **Object interaction**: Grab and release items either directly or remotely.
- **Experimental-ready structure**: Designed for future empirical studies comparing interaction methods and sensory setups.

## 🧪 Experimental Design (Not Executed Yet)

The system was prepared for a rigorous **within-subjects cross** experimental design to analyze:
- **Presence** (using Igroup Presence Questionnaire - IPQ)
- **Cognitive load**
- **User satisfaction**
- **Performance metrics** (time, errors)

The study includes **stratified randomization** and blocking based on users' susceptibility to motion sickness.

## 👨‍💻 Author

**Sebastian Gonzalo Andrade Guanoquiza**  
Tutor: Dr. Angélica de Antonio Jiménez  
Universidad Politécnica de Madrid – ETSI Informáticos  
July 2025

